{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gmail.com', 'yahoo.com', 'hotmail.com', 'ineuron.ai', 'outlook.com']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "**Question 1.** Write a python program to find out the words after '@' from the below sentences with the use of regex.\n",
    "\n",
    "\"xyz@gmail.com\",\n",
    "\"abc@yahoo.com\",\n",
    "\"xyz@hotmail.com\",\n",
    "\"abc@ineuron.ai\",\n",
    "\"xyz@outlook.com\"\n",
    "'''\n",
    "\n",
    "import re\n",
    "\n",
    "lst=[\"xyz@gmail.com\",\"abc@yahoo.com\",\"xyz@hotmail.com\",\"abc@ineuron.ai\",\"xyz@outlook.com\"]\n",
    "\n",
    "[re.split('@',lst[i])[1] for i in range(len(lst))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#**Question 2.** Write a python program with the use of regex to take out the word \"New\" from the following sentence.\n",
    "\n",
    "text=\"New Delhi is the capital of India\"\n",
    "print(re.split('\\s',text)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in india,  people got affected with corona virus and  are died.\n"
     ]
    }
   ],
   "source": [
    "#*Question 3.** Create one python program in which you have to lowercase the sentence first and than delete digits from the following sentence.\n",
    "\n",
    "text=\"In India, 184 people got affected with Corona virus and 4 are died.\"\n",
    "\n",
    "text=text.lower()\n",
    "text=re.sub('\\d','',text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**Question 4.**Do stemming, lemmatization and tokenization from the following sentence.\n",
    "\n",
    "text=\"I hope that, when I have built up my savings, I will be able to travel to Hawai.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'hope', 'that', ',', 'when', 'I', 'have', 'built', 'up', 'my', 'save', ',', 'I', 'will', 'be', 'abl', 'to', 'travel', 'to', 'hawai', '.']\n",
      "['I', 'hope', 'that', ',', 'when', 'I', 'have', 'built', 'up', 'my', 'saving', ',', 'I', 'will', 'be', 'able', 'to', 'travel', 'to', 'Hawai', '.']\n",
      "['I', 'hope', 'that', ',', 'when', 'I', 'have', 'built', 'up', 'my', 'savings', ',', 'I', 'will', 'be', 'able', 'to', 'travel', 'to', 'Hawai', '.']\n"
     ]
    }
   ],
   "source": [
    "ps=PorterStemmer()\n",
    "lemma=WordNetLemmatizer()\n",
    "text_tokens = word_tokenize(text) \n",
    "stems = [ps.stem(word) for word in text_tokens] \n",
    "lemma1=[lemma.lemmatize(word)  for word in text_tokens]\n",
    "print(stems)\n",
    "print(lemma1)\n",
    "print(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'l', 'N', 'n', 'y']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#**Question 5.** Create one python program from the following sentence.\n",
    "\n",
    "text=\"I love NLP, not you\"\n",
    "\n",
    "lst=re.split('\\s',text)\n",
    "[lst[i][0] for i in range(len(lst))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXTBLOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Susie', 'NNP'),\n",
       " ('works', 'VBZ'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('shoeshine', 'NN'),\n",
       " ('shop', 'NN'),\n",
       " ('Where', 'WRB'),\n",
       " ('she', 'PRP'),\n",
       " ('shines', 'VBZ'),\n",
       " ('she', 'PRP'),\n",
       " ('sits', 'VBZ'),\n",
       " ('and', 'CC'),\n",
       " ('where', 'WRB'),\n",
       " ('she', 'PRP'),\n",
       " ('sits', 'VBZ'),\n",
       " ('she', 'PRP'),\n",
       " ('shines', 'NNS')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#**Question 1.** Write a python program using Textblob in which find out the parts-of-speech(pos) tagging from the following sentence.\n",
    "\n",
    "text=TextBlob(\"Susie works in a shoeshine shop. Where she shines she sits, and where she sits she shines\")\n",
    "\n",
    "text.pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Question 2.** What is Wordlist? And, how it is different than tokenization?\n",
    "\n",
    "Wordlist is just python list with additional methods , it doesnt include spaces as tokens like tokization does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#**Question 3.** Write a python program using the textblob to find out the count of the common words from the following sentence.\n",
    "#Find it out how many times 'wood' came in the sentence.\n",
    "\n",
    "text=TextBlob(\"How much wood would a woodchuck chuck if a woodchuck could chuck wood?.He would chuck, he would, as much as he could, and chuck as much wood.As a woodchuck would if a woodchuck could chuck wood\")\n",
    "text.word_counts['wood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"ಡೇಟಾ ಹೊಸ ತೈಲ, ಎ.ಐ ಕೊನೆಯ ಆವಿಷ್ಕಾರ, ಅವಳು ಕಡಲ ತೀರದಿಂದ ಸೀಶೆಲ್ಗಳನ್ನು ಮಾರುತ್ತಾಳೆ, ಅವನು ಮೂರು ಉಚಿತ ಥ್ರೋಗಳನ್ನು ಎಸೆದನು\")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#**Question 4.** Translate the following sentences in your own language using the textblob.\n",
    "\n",
    "text=TextBlob(\"Data is a new oil,A.I is the last invention,She sells seashells by the seashore, He threw three free throws\")\n",
    "text.translate(to='kn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What [('That', 0.8001534821257275), ('What', 0.1925561169022191), ('Hat', 0.006714843000575558), ('Chat', 0.0005755579714779049)]\n",
      "I [('I', 1.0)]\n",
      "Learned [('Learned', 0.9090909090909091), ('Earned', 0.09090909090909091)]\n",
      "from [('from', 1.0)]\n",
      "Scarping [('Carping', 1.0)]\n",
      "16K [('16K', 0.0)]\n",
      "data [('data', 1.0)]\n"
     ]
    }
   ],
   "source": [
    "#**Question 5.** Create a spell checker program using the textblob library with using your own sentences.\n",
    "\n",
    "\n",
    "text=TextBlob('What I Learned from Scarping 16K data')\n",
    "for i in range(len(text.words)):\n",
    "    print(text.words[i],text.words[i].spellcheck())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_md')\n",
    "doc=nlp(\"ship car truck motor-bike jeep hagskdshd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship ship 1.0\n",
      "ship car 0.2815587\n",
      "ship truck 0.35367906\n",
      "ship motor 0.2741221\n",
      "ship - 0.03045519\n",
      "ship bike 0.19740233\n",
      "ship jeep 0.21036273\n",
      "ship hagskdshd 0.0\n",
      "car ship 0.2815587\n",
      "car car 1.0\n",
      "car truck 0.7113439\n",
      "car motor 0.5655214\n",
      "car - 0.1160374\n",
      "car bike 0.5357731\n",
      "car jeep 0.5652786\n",
      "car hagskdshd 0.0\n",
      "truck ship 0.35367906\n",
      "truck car 0.7113439\n",
      "truck truck 1.0\n",
      "truck motor 0.52424634\n",
      "truck - 0.059196077\n",
      "truck bike 0.48927912\n",
      "truck jeep 0.6284901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chinmay maganur\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\chinmay maganur\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\chinmay maganur\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck hagskdshd 0.0\n",
      "motor ship 0.2741221\n",
      "motor car 0.5655214\n",
      "motor truck 0.52424634\n",
      "motor motor 1.0\n",
      "motor - 0.010074199\n",
      "motor bike 0.46072814\n",
      "motor jeep 0.40830103\n",
      "motor hagskdshd 0.0\n",
      "- ship 0.03045519\n",
      "- car 0.1160374\n",
      "- truck 0.059196077\n",
      "- motor 0.010074199\n",
      "- - 1.0\n",
      "- bike 0.0737416\n",
      "- jeep -0.016787952\n",
      "- hagskdshd 0.0\n",
      "bike ship 0.19740233\n",
      "bike car 0.5357731\n",
      "bike truck 0.48927912\n",
      "bike motor 0.46072814\n",
      "bike - 0.0737416\n",
      "bike bike 1.0\n",
      "bike jeep 0.42305315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chinmay maganur\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\chinmay maganur\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\chinmay maganur\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bike hagskdshd 0.0\n",
      "jeep ship 0.21036273\n",
      "jeep car 0.5652786\n",
      "jeep truck 0.6284901\n",
      "jeep motor 0.40830103\n",
      "jeep - -0.016787952\n",
      "jeep bike 0.42305315\n",
      "jeep jeep 1.0\n",
      "jeep hagskdshd 0.0\n",
      "hagskdshd ship 0.0\n",
      "hagskdshd car 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chinmay maganur\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\chinmay maganur\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\chinmay maganur\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\chinmay maganur\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hagskdshd truck 0.0\n",
      "hagskdshd motor 0.0\n",
      "hagskdshd - 0.0\n",
      "hagskdshd bike 0.0\n",
      "hagskdshd jeep 0.0\n",
      "hagskdshd hagskdshd 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chinmay maganur\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\chinmay maganur\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\chinmay maganur\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "c:\\users\\chinmay maganur\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    for tok2 in doc:\n",
    "        print(token.text,tok2.text,token.similarity(tok2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chinmay maganur\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py:193: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">ship car truck motor-bike \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    jeep\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " hagskdshd</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chinmay maganur\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py:193: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"2c52c46d756c490f8a9f8a8d9b215afb-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">ship</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">car</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">truck</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">motor-</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">bike</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">jeep</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">hagskdshd</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c52c46d756c490f8a9f8a8d9b215afb-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c52c46d756c490f8a9f8a8d9b215afb-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c52c46d756c490f8a9f8a8d9b215afb-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c52c46d756c490f8a9f8a8d9b215afb-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c52c46d756c490f8a9f8a8d9b215afb-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c52c46d756c490f8a9f8a8d9b215afb-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c52c46d756c490f8a9f8a8d9b215afb-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c52c46d756c490f8a9f8a8d9b215afb-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c52c46d756c490f8a9f8a8d9b215afb-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c52c46d756c490f8a9f8a8d9b215afb-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c52c46d756c490f8a9f8a8d9b215afb-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c52c46d756c490f8a9f8a8d9b215afb-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "displacy.serve(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What is Word vector? And, how could you convert words into vector?\n",
    "\n",
    "Its a multidimensional representation  of  words interms of vectors ,words  are coverted into vectors using word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Define Vocab, hashes and lexemes in your own word.Define Vocab, hashes and lexemes in your own word.\n",
    "\n",
    "vocab-Its where spacy stores data\n",
    "hashes- spacy uses hasing technq to store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hashvalue forfootball 1941715343824527815\n",
      "using hash value football\n"
     ]
    }
   ],
   "source": [
    "doc=nlp('football')\n",
    "print('hashvalue forfootball',doc.vocab.strings['football'])\n",
    "print('using hash value',doc.vocab.strings[1941715343824527815])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
